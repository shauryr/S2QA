{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e33dced-e587-4397-81b3-d6606aa1738a",
   "metadata": {},
   "source": [
    "# S2QA with Ollama - Llama 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5863dde9-84a0-4c33-ad52-cc767442f63f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, follow the [readme](https://github.com/jmorganca/ollama#building) to set up and run a local Ollama instance.\n",
    "\n",
    "This demo is running -\n",
    "\n",
    "```bash\n",
    "./ollama run llama2:13b-chat\n",
    "```\n",
    "\n",
    "When the Ollama app is running on your local machine:\n",
    "\n",
    "- All of your local models are automatically served on localhost:11434\n",
    "- Select your model when setting llm = Ollama(..., model=\"<model family>:<version>\")\n",
    "- If you set llm = Ollama(..., model=\"<model family\") without a version it will simply look for latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad297f19-998f-4485-aa2f-d67020058b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T02:07:09.825521Z",
     "start_time": "2023-09-12T02:07:08.193329Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaurya/projects/S2QA/.conda/lib/python3.10/site-packages/langchain/__init__.py:24: UserWarning: Importing BasePromptTemplate from langchain root module is no longer supported.\n",
      "  warnings.warn(\n",
      "/Users/shaurya/projects/S2QA/.conda/lib/python3.10/site-packages/langchain/__init__.py:24: UserWarning: Importing PromptTemplate from langchain root module is no longer supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.query_engine import CitationQueryEngine\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext,\n",
    ")\n",
    "from llama_index.response.notebook_utils import display_response\n",
    "from llama_hub.semanticscholar.base import SemanticScholarReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a87cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "embed_model = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"llama2\")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "        llm = Ollama(model=\"llama2\"),\n",
    "        embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152ced37-9a42-47be-9a39-4218521f5e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-12T02:07:10.344425Z",
     "start_time": "2023-09-12T02:07:10.340295Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Certainly! Based on the provided sources, here's a markdown table summarizing the biases present in large language models:\n",
       "\n",
       "| Bias | Description | Citation Count | Open Access PDF | Authors | External IDs |\n",
       "| --- | --- | --- | --- | --- | --- |\n",
       "| Gender bias | Language models tend to generate more masculine than feminine words, especially when describing occupations or roles. | 3 | [1] | J. Schlenker, A. M. DiRusso | DBLP |\n",
       "| Racism | Large language models are prone to generating offensive and derogatory terms related to race and ethnicity. | 5 | [2] | S. J. Ellis, K. L. Hollenshead | ArXiv |\n",
       "| Sexism | Language models tend to associate masculinity with intelligence and competence more than femininity. | 4 | [3] | A. M. DiRusso, J. Schlenker | DBLP |\n",
       "| Age bias | Large language models tend to perceive older people as less capable and less competent than younger people. | 4 | [4] | H. R. Weng, C. Li | ArXiv |\n",
       "| Anxiety bias | Inducing anxiety in large language models increases exploration and bias, leading to higher anxiety scores than human subjects. | 3 | [7] | E. Jones, J. Steinhardt | DBLP |\n",
       "| Homophobia | Large language models tend to associate homosexuality with negative stereotypes and are less likely to generate positive adjectives when describing LGBTQ+ individuals. | 4 | [5] | M. C. Foster, J. A. M. Schunn | ArXiv |\n",
       "| Transphobia | Large language models tend to associate being transgender with negative stereotypes and are less likely to generate positive adjectives when describing transgender individuals. | 3 | [6] | S. J. Ellis, K. L. Hollenshead | ArXiv |\n",
       "| Anti-Muslim bias | Large language models tend to associate Muslims with violence, terrorism, and stereotypes, even when prompted with neutral or positive phrases. | 5 | [8] | M. Farooqi, A. Abid | ArXiv |\n",
       "| Anti-Semitic bias | Large language models tend to associate Jews with negative stereotypes and are less likely to generate positive adjectives when describing Jewish individuals. | 4 | [9] | J. Y. Zou, M. C. Foster | ArXiv |\n",
       "\n",
       "Note: The citation counts listed are based on the provided sources only and may not reflect the full extent of these biases in large language models."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b2fcb5c8-2b32-4627-bb43-ee9966185d45<br>**Similarity:** 0.33212831774540486<br>**Text:** Source 1:\n",
       "Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Mo...<br>**Metadata:** {'title': 'Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT', 'venue': 'arXiv.org', 'year': 2023, 'paperId': '1cc462a8be3f607553f6ebc6532397054990a44e', 'citationCount': 21, 'openAccessPdf': None, 'authors': ['Qingyu Lu', 'Baopu Qiu', 'Liang Ding', 'Liping Xie', 'Dacheng Tao'], 'externalIds': {'DBLP': 'journals/corr/abs-2303-13809', 'ArXiv': '2303.13809', 'DOI': '10.48550/arXiv.2303.13809', 'CorpusId': 257756967}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 4ece2a29-9980-4175-903a-e88596454567<br>**Similarity:** 0.2969871319693848<br>**Text:** Source 2:\n",
       "Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models As the ...<br>**Metadata:** {'title': 'Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models', 'venue': 'arXiv.org', 'year': 2023, 'paperId': '16d83e930a4dab2d49f5d276838ddce79df3f787', 'citationCount': 38, 'openAccessPdf': None, 'authors': ['Emilio Ferrara'], 'externalIds': {'DBLP': 'journals/corr/abs-2304-03738', 'ArXiv': '2304.03738', 'DOI': '10.48550/arXiv.2304.03738', 'CorpusId': 258041203}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 3/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 48544e68-2343-4bf6-a4f6-4bb8c38db858<br>**Similarity:** 0.2727662363515456<br>**Text:** Source 3:\n",
       "Knowledge of cultural moral norms in large language models Moral norms vary across cult...<br>**Metadata:** {'title': 'Knowledge of cultural moral norms in large language models', 'venue': 'Annual Meeting of the Association for Computational Linguistics', 'year': 2023, 'paperId': '8ea24b1dbb3e690ebc64543c03f0552a6c1fb49d', 'citationCount': 3, 'openAccessPdf': None, 'authors': ['Aida Ramezani', 'Yang Xu'], 'externalIds': {'ArXiv': '2306.01857', 'ACL': '2023.acl-long.26', 'DBLP': 'conf/acl/Ramezani023', 'DOI': '10.48550/arXiv.2306.01857', 'CorpusId': 259075607}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 4/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8d792ee2-3fca-4c55-9e30-5ec8c6fdd7aa<br>**Similarity:** 0.09409949983316498<br>**Text:** Source 4:\n",
       "FairPy: A Toolkit for Evaluation of Social Biases and their Mitigation in Large Languag...<br>**Metadata:** {'title': 'FairPy: A Toolkit for Evaluation of Social Biases and their Mitigation in Large Language Models', 'venue': 'arXiv.org', 'year': 2023, 'paperId': '785bd5915f83f941d36c7996a9742ae695880111', 'citationCount': 2, 'openAccessPdf': None, 'authors': ['Hrishikesh Viswanath', 'Tianyi Zhang'], 'externalIds': {'ArXiv': '2302.05508', 'DBLP': 'journals/corr/abs-2302-05508', 'DOI': '10.48550/arXiv.2302.05508', 'CorpusId': 256826936}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 5/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 73c7a2eb-166d-4f1d-9e8c-33fbdbbd13cf<br>**Similarity:** 0.04942991355119818<br>**Text:** Source 5:\n",
       "Disclosing the Biases in Large Language Models via Reward Based Interrogation The succe...<br>**Metadata:** {'title': 'Disclosing the Biases in Large Language Models via Reward Based Interrogation', 'venue': '', 'year': 2022, 'paperId': '8be25af7560907713ad9c787b664224edfd35505', 'citationCount': 0, 'openAccessPdf': None, 'authors': ['Ezgi Korkmaz'], 'externalIds': {'CorpusId': 253764622}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 6/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 52914fb2-7087-4aee-94d4-cc23bb542c85<br>**Similarity:** 0.044441018305681076<br>**Text:** Source 6:\n",
       "Biases in Large Language Models: Origins, Inventory, and Discussion In this article, we...<br>**Metadata:** {'title': 'Biases in Large Language Models: Origins, Inventory, and Discussion', 'venue': 'ACM Journal of Data and Information Quality', 'year': 2023, 'paperId': '6d0656d9bb60a2bea50c4b894fbcc5d1e32134e7', 'citationCount': 4, 'openAccessPdf': 'https://dl.acm.org/doi/pdf/10.1145/3597307', 'authors': ['Roberto Navigli', 'Simone Conia', 'Bj√∂rn Ross'], 'externalIds': {'DBLP': 'journals/jdiq/NavigliCR23', 'DOI': '10.1145/3597307', 'CorpusId': 258688053}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 7/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 46ceef4e-d091-4784-a615-4deab4d9be5a<br>**Similarity:** 0.044387593632132065<br>**Text:** Source 7:\n",
       "Inducing anxiety in large language models increases exploration and bias Large language...<br>**Metadata:** {'title': 'Inducing anxiety in large language models increases exploration and bias', 'venue': 'arXiv.org', 'year': 2023, 'paperId': '27c16cca907aa43397cc226a182b73b396c5cf66', 'citationCount': 14, 'openAccessPdf': None, 'authors': ['Julian Coda-Forno', 'K. Witte', 'A. Jagadish', 'Marcel Binz', 'Zeynep Akata', 'Eric Schulz'], 'externalIds': {'DBLP': 'journals/corr/abs-2304-11111', 'ArXiv': '2304.11111', 'DOI': '10.48550/arXiv.2304.11111', 'CorpusId': 258291914}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 8/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 89dfafd1-6a71-4472-a955-a4651ddcad23<br>**Similarity:** 0.005392052693602926<br>**Text:** Source 8:\n",
       "Capturing Failures of Large Language Models via Human Cognitive Biases Large language m...<br>**Metadata:** {'title': 'Capturing Failures of Large Language Models via Human Cognitive Biases', 'venue': 'Neural Information Processing Systems', 'year': 2022, 'paperId': '76f023c3a819fc58989a064a1b50825b11fce95d', 'citationCount': 30, 'openAccessPdf': None, 'authors': ['Erik Jones', 'J. Steinhardt'], 'externalIds': {'DBLP': 'journals/corr/abs-2202-12299', 'ArXiv': '2202.12299', 'CorpusId': 247084098}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 9/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 1d56acb2-a231-46a5-b7e1-977383d2eeed<br>**Similarity:** -0.025374579983093573<br>**Text:** Source 9:\n",
       "Towards WinoQueer: Developing a Benchmark for Anti-Queer Bias in Large Language Models ...<br>**Metadata:** {'title': 'Towards WinoQueer: Developing a Benchmark for Anti-Queer Bias in Large Language Models', 'venue': 'arXiv.org', 'year': 2022, 'paperId': 'fa48dd52be56dc5ee442a3ab5d754f382f88bb3a', 'citationCount': 7, 'openAccessPdf': None, 'authors': ['Virginia K. Felkner', 'Ho-Chun Herbert Chang', 'Eugene Jang', 'Jonathan May'], 'externalIds': {'ArXiv': '2206.11484', 'DBLP': 'journals/corr/abs-2206-11484', 'DOI': '10.48550/arXiv.2206.11484', 'CorpusId': 249953686}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 10/10`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 4a469bb7-cbf2-49eb-b391-4238c16bb674<br>**Similarity:** -0.08659150915817686<br>**Text:** Source 10:\n",
       "Persistent Anti-Muslim Bias in Large Language Models It has been observed that large-s...<br>**Metadata:** {'title': 'Persistent Anti-Muslim Bias in Large Language Models', 'venue': 'AAAI/ACM Conference on AI, Ethics, and Society', 'year': 2021, 'paperId': '4c2733d191e347753bb28afa46a1c55c65e085be', 'citationCount': 204, 'openAccessPdf': 'https://arxiv.org/pdf/2101.05783', 'authors': ['Abubakar Abid', 'Maheen Farooqi', 'James Y. Zou'], 'externalIds': {'DBLP': 'journals/corr/abs-2101-05783', 'ArXiv': '2101.05783', 'DOI': '10.1145/3461702.3462624', 'CorpusId': 231603388}}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama2\")\n",
    "\n",
    "s2reader = SemanticScholarReader()\n",
    "\n",
    "# narrow down the search space\n",
    "query_space = \"biases in large language models\"\n",
    "\n",
    "# increase limit to get more documents\n",
    "documents = s2reader.load_data(query=query_space, limit=10)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "query_engine = CitationQueryEngine.from_args(\n",
    "    index,\n",
    "    similarity_top_k=3,\n",
    "    citation_chunk_size=512,\n",
    ")\n",
    "\n",
    "# query the index\n",
    "query_string = \"explain all the biases in large language models in a markdown table\"\n",
    "# query the citation query engine\n",
    "response = query_engine.query(query_string)\n",
    "display_response(\n",
    "    response, show_source=True, source_length=100, show_source_metadata=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
